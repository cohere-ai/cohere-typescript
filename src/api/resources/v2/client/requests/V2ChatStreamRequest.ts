/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as Cohere from "../../../../index";

/**
 * @example
 *     {
 *         model: "string",
 *         messages: [{
 *                 role: "assistant",
 *                 toolCalls: [{
 *                         id: "string",
 *                         type: "function",
 *                         function: {
 *                             name: "string",
 *                             arguments: "string"
 *                         }
 *                     }],
 *                 toolPlan: "string",
 *                 content: [{
 *                         text: "string"
 *                     }],
 *                 citations: [{
 *                         start: "string",
 *                         end: "string",
 *                         text: "string",
 *                         sources: [{
 *                                 type: "tool",
 *                                 id: "string",
 *                                 toolOutput: {
 *                                     "string": {
 *                                         "key": "value"
 *                                     }
 *                                 }
 *                             }]
 *                     }]
 *             }],
 *         tools: [{
 *                 type: "function",
 *                 function: {
 *                     name: "string",
 *                     description: "string",
 *                     parameters: {
 *                         "string": {
 *                             "key": "value"
 *                         }
 *                     }
 *                 }
 *             }],
 *         toolChoice: Cohere.V2ChatStreamRequestToolChoice.Auto,
 *         citationMode: Cohere.V2ChatStreamRequestCitationMode.Fast,
 *         truncationMode: Cohere.V2ChatStreamRequestTruncationMode.Off,
 *         responseFormat: {
 *             type: "json_object",
 *             schema: {
 *                 "string": {
 *                     "key": "value"
 *                 }
 *             }
 *         },
 *         maxTokens: 1,
 *         stopSequences: ["string"],
 *         maxInputTokens: 1,
 *         temperature: 1.1,
 *         seed: 1,
 *         frequencyPenalty: 1.1,
 *         presencePenalty: 1.1,
 *         k: 1,
 *         p: 1,
 *         returnPrompt: true
 *     }
 */
export interface V2ChatStreamRequest {
    /** The model to use for the chat. */
    model: string;
    messages: Cohere.ChatMessages;
    tools?: Cohere.Tool2[];
    toolChoice?: Cohere.V2ChatStreamRequestToolChoice;
    citationMode?: Cohere.V2ChatStreamRequestCitationMode;
    truncationMode?: Cohere.V2ChatStreamRequestTruncationMode;
    responseFormat?: Cohere.V2ChatStreamRequestResponseFormat;
    /** The maximum number of tokens to generate. */
    maxTokens?: number;
    /** A list of strings that the model will stop generating at. */
    stopSequences?: string[];
    /** The maximum number of tokens to feed into the model. */
    maxInputTokens?: number;
    /** The temperature of the model. */
    temperature?: number;
    seed?: number;
    /** The frequency penalty of the model. */
    frequencyPenalty?: number;
    /** The presence penalty of the model. */
    presencePenalty?: number;
    k?: number;
    p?: number;
    /** Whether to return the prompt in the response. */
    returnPrompt?: boolean;
}
