/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as serializers from "../..";
import * as Cohere from "../../../api";
import * as core from "../../../core";

export const ChatRequest: core.serialization.Schema<serializers.ChatRequest.Raw, Cohere.ChatRequest> =
    core.serialization.object({
        message: core.serialization.string(),
        model: core.serialization.string().optional(),
        preamble: core.serialization.string().optional(),
        chatHistory: core.serialization.property(
            "chat_history",
            core.serialization
                .list(core.serialization.lazyObject(async () => (await import("../..")).ChatMessage))
                .optional()
        ),
        conversationId: core.serialization.property("conversation_id", core.serialization.string().optional()),
        promptTruncation: core.serialization.property(
            "prompt_truncation",
            core.serialization.lazy(async () => (await import("../..")).ChatRequestPromptTruncation).optional()
        ),
        connectors: core.serialization
            .list(core.serialization.lazyObject(async () => (await import("../..")).ChatConnector))
            .optional(),
        searchQueriesOnly: core.serialization.property("search_queries_only", core.serialization.boolean().optional()),
        documents: core.serialization
            .list(core.serialization.lazy(async () => (await import("../..")).ChatDocument))
            .optional(),
        temperature: core.serialization.number().optional(),
        maxTokens: core.serialization.property("max_tokens", core.serialization.number().optional()),
        k: core.serialization.number().optional(),
        p: core.serialization.number().optional(),
        seed: core.serialization.number().optional(),
        stopSequences: core.serialization.property(
            "stop_sequences",
            core.serialization.list(core.serialization.string()).optional()
        ),
        frequencyPenalty: core.serialization.property("frequency_penalty", core.serialization.number().optional()),
        presencePenalty: core.serialization.property("presence_penalty", core.serialization.number().optional()),
        rawPrompting: core.serialization.property("raw_prompting", core.serialization.boolean().optional()),
        tools: core.serialization
            .list(core.serialization.lazyObject(async () => (await import("../..")).Tool))
            .optional(),
        toolResults: core.serialization.property(
            "tool_results",
            core.serialization
                .list(core.serialization.lazyObject(async () => (await import("../..")).ChatRequestToolResultsItem))
                .optional()
        ),
    });

export declare namespace ChatRequest {
    interface Raw {
        message: string;
        model?: string | null;
        preamble?: string | null;
        chat_history?: serializers.ChatMessage.Raw[] | null;
        conversation_id?: string | null;
        prompt_truncation?: serializers.ChatRequestPromptTruncation.Raw | null;
        connectors?: serializers.ChatConnector.Raw[] | null;
        search_queries_only?: boolean | null;
        documents?: serializers.ChatDocument.Raw[] | null;
        temperature?: number | null;
        max_tokens?: number | null;
        k?: number | null;
        p?: number | null;
        seed?: number | null;
        stop_sequences?: string[] | null;
        frequency_penalty?: number | null;
        presence_penalty?: number | null;
        raw_prompting?: boolean | null;
        tools?: serializers.Tool.Raw[] | null;
        tool_results?: serializers.ChatRequestToolResultsItem.Raw[] | null;
    }
}
